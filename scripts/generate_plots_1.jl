# This script generates plots from the simulations outcomes generated by 1_script.jl
# Usage:
# 1) navigate to the project directory 'rl_cheap_talk' 
# 2) run 'julia --threads NUM_THREADS scripts/generate_plots_1.jl -i INPUT_DIR'
#	 replacing NUM_THREADS with the desired number of threads 
#    and INPUT_DIR with the output directory of 1_script.jl 

using PGFPlotsX
using StatsBase
using Base.Threads

include(joinpath(pwd(),"scripts/plots.jl"))
include(joinpath(pwd(),"scripts/read_data.jl"))

# parse terminal config
const scrpt_config = parse_commandline("out_basecase", 0.005f0)
# define set of biases 
const set_biases = collect(0.00f0:scrpt_config["step_bias"]:0.5f0)
# define input dir 
const input_dir = joinpath(pwd(), scrpt_config["in_dir"])

# navigate to relevant subdir 
dirs = readdir(input_dir, join = true)
dirs = dirs[isdir.(dirs)]
dirs = setdiff(dirs,joinpath.(input_dir,["pdf", "temp", "tikz"]))
dir_id = 1
if length(dirs) > 1
	println("\nlist of directories: ")
	for (dir_id, dir) in enumerate(dirs)
		println(dir_id,": ", split(dir,"/")[end])
	end
	while true
		print("select directory: ")
		global dir_id = parse(Int, readline())
		dir_id in keys(dirs) && break
	end
end

println("\nInput dir: ", scrpt_config["in_dir"])

# read data and compute equilibria 
_, extracted_data = read_data(dirs[dir_id])
n_biases_nash = 1001
set_nash, best_nash = get_equilibria(n_biases_nash)

# unpacking data
policy_s = cat(extracted_data["policy_s"]...,dims=4);
policy_r = cat(extracted_data["policy_r"]...,dims=4);
induced_actions = cat(extracted_data["induced_actions"]...,dims=4);
n_episodes = cat(extracted_data["n_episodes"]...,dims=2);
is_converged = cat(extracted_data["is_converged"]...,dims=2);
expected_reward_s = cat(extracted_data["expected_reward_s"]...,dims=2);
expected_reward_r = cat(extracted_data["expected_reward_r"]...,dims=2);
mutual_information = cat(extracted_data["mutual_information"]...,dims=2);
absolute_error_s = cat(extracted_data["absolute_error_s"]...,dims=2);
absolute_error_r = cat(extracted_data["absolute_error_r"]...,dims=2);
max_absolute_error = cat(extracted_data["max_absolute_error"]...,dims=2);
n_on_path_messages = cat(extracted_data["n_on_path_messages"]...,dims=2);
max_mass_on_suboptim_s = cat(extracted_data["max_mass_on_suboptim_s"]...,dims=2);
max_mass_on_suboptim_r = cat(extracted_data["max_mass_on_suboptim_r"]...,dims=2);
max_max_mass_on_suboptim = cat(extracted_data["max_max_mass_on_suboptim"]...,dims=2);
is_partitional = cat(extracted_data["is_partitional"]...,dims=2);
n_effective_messages = cat(extracted_data["n_effective_messages"]...,dims=2);

babbling_reward_s = extracted_data["babbling_reward_s"];
babbling_reward_r = extracted_data["babbling_reward_r"];
expected_reward_s_best = best_nash["expected_reward_s"];
expected_reward_r_best = best_nash["expected_reward_r"];
mutual_information_best = best_nash["mutual_information"];
expected_reward_s_nash = set_nash["expected_reward_s"];
expected_reward_r_nash = set_nash["expected_reward_r"];
mutual_information_nash = set_nash["mutual_information"];
induced_actions_nash = set_nash["induced_actions"];

n_simulations, n_biases = size(n_episodes)
set_biases_nash = range(0.0f0,0.5f0,n_biases_nash)


# COMPUTATIONS

# (a) gamma and epsilon nash flags
is_gamma_nash = max_max_mass_on_suboptim .< 1f-2
is_epsilon_nash = max_absolute_error .< 1f-4

# (b) compute modal policies for converged sessions and for sessions converged to a gamma nash 

modal_policy_s = fill(NaN32, n_states,n_messages,n_biases)
modal_policy_r = fill(NaN32, n_messages,n_actions,n_biases)
modal_induced_actions = fill(NaN32, n_states,n_actions,n_biases)
modal_mutual_information = fill(NaN32, n_biases)
modal_expected_reward_s = fill(NaN32, n_biases)
modal_expected_reward_r = fill(NaN32, n_biases)
freq_ia = zeros(Float32,n_biases)
modal_policy_s_nash = fill(NaN32, n_states,n_messages,n_biases)
modal_policy_r_nash = fill(NaN32, n_messages,n_actions,n_biases)
modal_induced_actions_nash = fill(NaN32, n_states,n_actions,n_biases)
modal_mutual_information_nash = fill(NaN32, n_biases)
modal_expected_reward_s_nash = fill(NaN32, n_biases)
modal_expected_reward_r_nash = fill(NaN32, n_biases)
freq_ia_nash = zeros(Float32,n_biases)
for bias_idx in 1:n_biases
	global bias = set_biases[bias_idx]
	global reward_matrix_s, reward_matrix_r = gen_reward_matrix()
	# modal induced actions for converged sessions
	induced_actions_ = induced_actions[:,:,:,bias_idx]
	unique_induced_actions = unique(induced_actions_,dims=3)
	freq_induced_actions  =	[count(all(induced_actions_ .== induced_actions, dims=1:2)) for induced_actions in eachslice(unique_induced_actions, dims=3)]
	modal_induced_actions[:,:,bias_idx] = unique_induced_actions[:,:,argmax(freq_induced_actions)]
	freq_ia[bias_idx] = maximum(freq_induced_actions)
 	modal_induced_actions_idx = findfirst(all(induced_actions_ .== modal_induced_actions[:,:,bias_idx],dims=1:2)[:])
	modal_policy_s[:,:,bias_idx] = policy_s[:,:,modal_induced_actions_idx,bias_idx]
	modal_policy_r[:,:,bias_idx] = policy_r[:,:,modal_induced_actions_idx,bias_idx]
	modal_mutual_information[bias_idx] = get_mutual_information(modal_policy_s[:,:,bias_idx])
	modal_expected_reward_s[bias_idx], modal_expected_reward_r[bias_idx] = get_expected_rewards(modal_induced_actions[:,:,bias_idx])

	# modal policy for sessions converged to a gamma nash
	any(is_gamma_nash[:,bias_idx]) || continue
	induced_actions_ = induced_actions[:,:,:,bias_idx]
	unique_induced_actions = unique(induced_actions_,dims=3)
	freq_induced_actions  =	[count(all(induced_actions_ .== induced_actions, dims=1:2)) for induced_actions in eachslice(unique_induced_actions, dims=3)]
	modal_induced_actions_nash[:,:,bias_idx] = unique_induced_actions[:,:,argmax(freq_induced_actions)]
	freq_ia_nash[bias_idx] = maximum(freq_induced_actions)
 	modal_induced_actions_idx = findfirst(all(induced_actions_ .== modal_induced_actions[:,:,bias_idx],dims=1:2)[:])
	modal_policy_s_nash[:,:,bias_idx] = policy_s[:,:,modal_induced_actions_idx,bias_idx]
	modal_policy_r_nash[:,:,bias_idx] = policy_r[:,:,modal_induced_actions_idx,bias_idx]
	modal_mutual_information_nash[bias_idx] = get_mutual_information(modal_policy_s[:,:,bias_idx])
	modal_expected_reward_s_nash[bias_idx], modal_expected_reward_r_nash[bias_idx] = get_expected_rewards(modal_induced_actions[:,:,bias_idx])
end

# (c) compute range of existence of monotone partitional equilibria (identified by their induced actions)
unique_induced_actions_nash = unique(cat(unique(induced_actions_nash)...,dims=3),dims=3)
n_unique_induced_actions = size(unique_induced_actions_nash,3)
existence_range = zeros(Float32, n_unique_induced_actions,2)
set_biases_nash = range(0.0f0,0.5f0,n_biases_nash)
unique_mutual_information_nash = zeros(Float32, n_unique_induced_actions)
for ia_idx in 1:n_unique_induced_actions
	exists = falses(n_biases_nash)
	for bias_idx in 1:n_biases_nash
		nash_idx = all(unique_induced_actions_nash[:,:,ia_idx] .== induced_actions_nash[bias_idx], dims=1:2)[:]
		exists[bias_idx] = any(nash_idx) || continue
		unique_mutual_information_nash[ia_idx] = mutual_information_nash[bias_idx][nash_idx][1]
	end
	existence_range[ia_idx,:] .= set_biases_nash[[findfirst(exists), findlast(exists)]]
end
perm = sortperm(-unique_mutual_information_nash)
unique_mutual_information_nash = unique_mutual_information_nash[perm]
existence_range = existence_range[perm,:]



# GENERATE PLOTS
push!(PGFPlotsX.CUSTOM_PREAMBLE, "\\usepgfplotslibrary{fillbetween}")
ratio = 4/3

# N EPISODES
pl_n_episodes = plot_avg(n_episodes; title = "episodes to converge",color = "blue", legend_pos = "out_bottom");
pl_n_episodes = plot_eq_bound!(pl_n_episodes,mutual_information_best);


####  DISTRIBUTION  #####
#########################
# note that distributions are fitted on a grid of n_steps intervals
# overlaying a benchmark value to the grid without snapping values to the grid might be misleading (identical y-values are not aligned)
# for this reason, best_mutual_information and best_expected_reward_r are snapped to the grid
# best_expected_reward_s is not snapped to the grid as it looks fine (and actually better, because is curved)

#MUTUAL INFORMATION 
pl_mutual_information = plot_dist(mutual_information; title = "normalized mutual information", 
													  legend = "simulations", 
													  #ylabel = raw"$I$",
													  color = "blue",
													  legend_pos = "out_bottom",
													  ymin=0, ymax=1, n_steps=65);
# interpolate benchmark points to heatmap grid (removes heatmap value distorsion)
pl_mutual_information = plot_interpolated_val!(pl_mutual_information, mutual_information_best; legend = "optimal", color = "red", style = "solid, line width=1.8pt", opacity = 0.4, ymin=0, ymax=1, n_steps=65);
#pl_mutual_information = plot_val!(pl_mutual_information, mutual_information_best; legend = "optimal", color = "red", style = "solid, line width=1.8pt", opacity = 0.4);
babbling_mutual_information = fill(mutual_information_best[end],length(set_biases))
pl_mutual_information = plot_val!(pl_mutual_information, babbling_mutual_information; legend = "babbling", color = "darkgray", style = "dotted");
pl_mutual_information = plot_eq_bound!(pl_mutual_information,mutual_information_best);

# EXPECTED REWARDS (SENDER)
group_pl_expected_reward_s = plot_dist(expected_reward_s; title = string(get_title_equation(1),"ex-ante expected reward (sender)"),
														  color = "blue", n_steps = 65);
group_pl_expected_reward_s = plot_val!(group_pl_expected_reward_s, expected_reward_s_best; color="red", style = "solid, line width=1.8pt", opacity = 0.4);
group_pl_expected_reward_s = plot_val!(group_pl_expected_reward_s, babbling_reward_s; color="darkgray", style = "dotted");
group_pl_expected_reward_s = plot_eq_bound!(group_pl_expected_reward_s,mutual_information_best);

# EXPECTED REWARDS (RECEIVER)
ymin = minimum(quantile_(expected_reward_r, 0.05, dims = 1))
ymax = maximum(quantile_(expected_reward_r, 0.95, dims = 1))
group_pl_expected_reward_r = plot_dist(expected_reward_r; title = string(get_title_equation(2),"ex-ante expected reward (receiver)"), 
														  legend = "simulations", 
														  color = "blue",
														  ymin=ymin, ymax=ymax, n_steps = 65);
group_pl_expected_reward_r = plot_interpolated_val!(group_pl_expected_reward_r, expected_reward_r_best; legend = "optimal", color = "red", style = "solid, line width=1.8pt", opacity = 0.4, ymin=ymin, ymax=ymax, n_steps=65);
group_pl_expected_reward_r = plot_val!(group_pl_expected_reward_r, babbling_reward_r; legend = "babbling", color = "darkgray", style = "dotted");
group_pl_expected_reward_r = plot_eq_bound!(group_pl_expected_reward_r,mutual_information_best);

# EXPECTED REWARDS (GROUP)
push!(group_pl_expected_reward_r.options, "legend style={legend columns = -1, legend to name={legend_group_expected_rewards}, column sep = 3.5pt}")
group_pl_expected_rewards = @pgf GroupPlot({group_style={group_size="2 by 1", raw"horizontal sep = 60pt" },}, group_pl_expected_reward_s, group_pl_expected_reward_r);



######  MODE (ALL) ######
#########################
# printing values for modal policies of sender and receiver 
# all converged sessions are considered 

# MUTUAL INFORMATION (with monotone partitional equilibria's values in grey)
pl_modal_mutual_information = init_tikz_axis(title="modal normalized mutual information", xlabel=raw"$b$");
for i in 1:length(unique_mutual_information_nash)
    start_point, end_point = existence_range[i, :]
    mi_value = unique_mutual_information_nash[i] 
    if mutual_information_best[set_biases_nash .== end_point][1] == mi_value # replace grey with red on benchmark
    	end_point_idx = findfirst(mutual_information_best .== mi_value) - 1
    	end_point_idx > 0 || continue	# totally replaced by benchmark
    	end_point = set_biases_nash[end_point_idx]
    end
    pl = @pgf Plot({no_marks, line_width="1.8pt", const_plot, color="gray", opacity = 0.3, forget_plot=(i!=1)}, Coordinates([(start_point, mi_value),(end_point, mi_value)]))
    push!(pl_modal_mutual_information, pl)    
end
add_legend!(pl_modal_mutual_information, "equilibria", "out_bottom")
plot_val!(pl_modal_mutual_information, mutual_information_best; legend = "optimal", color = "red", style = "solid, line width=1.8pt", opacity = 0.4);
plot_val!(pl_modal_mutual_information, modal_mutual_information; color="blue", style="solid, line width=0.9pt", legend = "modal outcome", opacity = 0.5);

# EXPECTED REWARDS (SENDER)
ymin, ymax = extrema(modal_expected_reward_s)
pl_modal_expected_reward_s = init_tikz_axis(title="ex-ante expected reward (sender)", xlabel=raw"$b$", ymin=ymin, ymax=ymax);
plot_val!(pl_modal_expected_reward_s, expected_reward_s_best; color = "red", style = "solid, line width=1.8pt", opacity = 0.4);
plot_val!(pl_modal_expected_reward_s, modal_expected_reward_s; color="blue", style="solid, line width=1pt", opacity = 0.5);
plot_val!(pl_modal_expected_reward_s, babbling_reward_s; color="darkgray", style = "dotted");
plot_eq_bound!(pl_modal_expected_reward_s,mutual_information_best);

# EXPECTED REWARDS (RECEIVER)
ymin, ymax = extrema(modal_expected_reward_r)
pl_modal_expected_reward_r = init_tikz_axis(title="ex-ante expected reward (receiver)", xlabel=raw"$b$", ymin=ymin, ymax=ymax);
plot_val!(pl_modal_expected_reward_r, expected_reward_r_best; legend = "optimal", color = "red", style = "solid, line width=1.8pt", opacity = 0.4);
plot_val!(pl_modal_expected_reward_r, modal_expected_reward_r; color="blue", style="solid, line width=1pt", legend = "modal outcome", opacity = 0.5);
plot_val!(pl_modal_expected_reward_r, babbling_reward_r; color="darkgray", style = "dotted");
plot_eq_bound!(pl_modal_expected_reward_r,mutual_information_best);

# EXPECTED REWARDS (GROUP)
push!(pl_modal_expected_reward_r.options, "legend style={legend columns = -1, legend to name={legend_group_expected_rewards}, column sep = 3.5pt}")
group_pl_modal_expected_rewards = @pgf GroupPlot({group_style={group_size="2 by 1", raw"horizontal sep = 60pt"},}, pl_modal_expected_reward_s, pl_modal_expected_reward_r);



#####  MODE (NASH) ######
#########################
# printing values for modal policies of sender and receiver 
# restricted to sessions converged to a gamma-nash

# MUTUAL INFORMATION (with monotone partitional equilibria's values in grey)
pl_modal_mutual_information_nash = init_tikz_axis(title="modal normalized mutual information", xlabel=raw"$b$");
for i in 1:length(unique_mutual_information_nash)
    start_point, end_point = existence_range[i, :]
    mi_value = unique_mutual_information_nash[i] 
    if mutual_information_best[set_biases_nash .== end_point][1] == mi_value # replace grey with red on benchmark
    	end_point_idx = findfirst(mutual_information_best .== mi_value) - 1
    	end_point_idx > 0 || continue	# totally replaced by benchmark
    	end_point = set_biases_nash[end_point_idx]
    end
    pl = @pgf Plot({no_marks, line_width="1.8pt", const_plot, color="gray", opacity = 0.3, forget_plot=(i!=1)}, Coordinates([(start_point, mi_value),(end_point, mi_value)]))
    push!(pl_modal_mutual_information_nash, pl)    
end
add_legend!(pl_modal_mutual_information_nash, "equilibria", "out_bottom")
plot_val!(pl_modal_mutual_information_nash, mutual_information_best; legend = "optimal", color = "red", style = "solid, line width=1.8pt", opacity = 0.4);
plot_val!(pl_modal_mutual_information_nash, modal_mutual_information_nash; color="blue", style="solid, line width=0.9pt", legend = "modal outcome", opacity = 0.5);

# EXPECTED REWARDS (SENDER)
ymin, ymax = extrema(filter(!isnan,modal_expected_reward_s_nash))
pl_modal_expected_reward_s_nash = init_tikz_axis(title="ex-ante expected reward (sender)", xlabel=raw"$b$", ymin=ymin, ymax=ymax);
plot_val!(pl_modal_expected_reward_s_nash, expected_reward_s_best; color = "red", style = "solid, line width=1.8pt", opacity = 0.4);
plot_val!(pl_modal_expected_reward_s_nash, modal_expected_reward_s_nash; color="blue", style="solid, line width=1pt", opacity = 0.5);
plot_val!(pl_modal_expected_reward_s_nash, babbling_reward_s; color="darkgray", style = "dotted");
plot_eq_bound!(pl_modal_expected_reward_s_nash,mutual_information_best);

# EXPECTED REWARDS (RECEIVER)
ymin, ymax = extrema(filter(!isnan,modal_expected_reward_r_nash))
pl_modal_expected_reward_r_nash = init_tikz_axis(title="ex-ante expected reward (receiver)", xlabel=raw"$b$", ymin=ymin, ymax=ymax);
plot_val!(pl_modal_expected_reward_r_nash, expected_reward_r_best; legend = "optimal", color = "red", style = "solid, line width=1.8pt", opacity = 0.4);
plot_val!(pl_modal_expected_reward_r_nash, modal_expected_reward_r_nash; color="blue", style="solid, line width=1pt", legend = "modal outcome", opacity = 0.5);
plot_val!(pl_modal_expected_reward_r_nash, babbling_reward_r; color="darkgray", style = "dotted");
plot_eq_bound!(pl_modal_expected_reward_r_nash,mutual_information_best);

# EXPECTED REWARDS (GROUP)
push!(pl_modal_expected_reward_r_nash.options, "legend style={legend columns = -1, legend to name={legend_group_expected_rewards}, column sep = 3.5pt}")
group_pl_modal_expected_rewards_nash = @pgf GroupPlot({group_style={group_size="2 by 1", raw"horizontal sep = 60pt"},}, pl_modal_expected_reward_s_nash, pl_modal_expected_reward_r_nash);



####  SUBOPTIMALITY #####
#########################

# ABSOLUTE ERROR (SENDER)
y_max = max(maximum(mean(absolute_error_s,dims = 1)), maximum(mean(absolute_error_r, dims = 1)))
#y_max = max(maximum(quantile_(extracted_data["absolute_error_s"], 0.95, dims = 1)), maximum(quantile_(extracted_data["absolute_error_r"], 0.95, dims = 1)))
pl_absolute_error_s = plot_avg(absolute_error_s;
								title = raw"potential ex-ante gain (sender)\\[-8pt]", 
								#title = raw"$U_S(\pi^S_*, \pi^R_\infty) - U_S(\pi^S_\infty, \pi^R_\infty)$ \\[-7pt]", 
								#ylabel = raw"$\epsilon_S$ ",
								additional = raw"tick scale binop=\times",
								color = "red",
								ymin=0, ymax = y_max,
								ci_flag = false,
								width = 0.35 * ratio, height = 0.35 * ratio^-1);
pl_absolute_error_s = plot_eq_bound!(pl_absolute_error_s,mutual_information_best);

# ABSOLUTE ERROR (RECEIVER)
pl_absolute_error_r = plot_avg(absolute_error_r;
								title = raw"potential ex-ante gain (receiver)\\[-8pt]", 
								#title = raw"$U_R(\pi^S_\infty, \pi^R_*) - U_S(\pi^S_\infty, \pi^R_\infty)$ \\[-7pt]", 
								#ylabel = raw"$\epsilon_R$ ",
								additional = raw"tick scale binop=\times",
								color = "blue",
								ymin=0, ymax = y_max,
								ci_flag = false,
								width = 0.35 * ratio, height = 0.35 * ratio^-1);
pl_absolute_error_r = plot_eq_bound!(pl_absolute_error_r,mutual_information_best);


# MAXIMUM MASS ON SUBOTPIMAL (SENDER)
y_max = max(maximum(mean(max_mass_on_suboptim_s, dims = 1)), maximum(mean(max_mass_on_suboptim_r, dims = 1)))
#y_max = max(maximum(quantile_(extracted_data["max_mass_on_suboptim_s"], 0.95, dims = 1)), maximum(quantile_(extracted_data["max_mass_on_suboptim_r"], 0.95, dims = 1)))
pl_max_mass_on_suboptim_s = plot_avg(max_mass_on_suboptim_s;
								title = raw"maximum probability on \\suboptimal actions (sender)",
								#title = raw"$\max_{\theta \in \Theta} \sum_{m \notin M^*(\theta)} \pi^S_\infty(m \mid \theta)$", 
								#ylabel = raw"$\gamma_S$", 						
								color = "red",
								ymin = 0, ymax = y_max,
								ci_flag = false,
								width = 0.35 * ratio, height = 0.35 * ratio^-1);
pl_max_mass_on_suboptim_s = plot_eq_bound!(pl_max_mass_on_suboptim_s,mutual_information_best);

# MAXIMUM MASS ON SUBOTPIMAL (RECEIVER)
pl_max_mass_on_suboptim_r = plot_avg(max_mass_on_suboptim_r;
								title = raw"maximum probability on \\suboptimal actions (receiver)",
								#title = raw"$\max_{m \in M} \sum_{a \notin A^*(m)} \pi^R_\infty(a \mid m)$", 
								#ylabel = raw"$\gamma_R$", 
								color = "blue",
								ymin = 0, ymax = y_max,
								ci_flag = false,
								width = 0.35 * ratio, height = 0.35 * ratio^-1);
pl_max_mass_on_suboptim_r = plot_eq_bound!(pl_max_mass_on_suboptim_r,mutual_information_best);


# ABSOLUTE ERROR AND MAXIMUM MASS ON SUBOTPIMAL (GROUP)
group_pl_errors = @pgf GroupPlot({group_style={group_size="2 by 2",raw"horizontal sep = 50pt, vertical sep = 60pt"},}, pl_max_mass_on_suboptim_s, pl_max_mass_on_suboptim_r, pl_absolute_error_s, pl_absolute_error_r);


# IS GAMMA NASH
pl_is_gamma_nash = plot_avg(is_gamma_nash;
								title = raw"$max\{\gamma_S,\gamma_R\} < 0.01$",
								color = "green!80!black",
								legend_pos = "out_bottom",
								additional = "axis y discontinuity=parallel",
								ymin=0.55,
								ci_flag = false,
								width = 0.35 * ratio, height = 0.35 * ratio^-1);
pl_is_gamma_nash = plot_eq_bound!(pl_is_gamma_nash,mutual_information_best);

# IS EPSILON NASH
pl_is_epsilon_nash = plot_avg(is_epsilon_nash;
								title = raw"$max\{\epsilon_S,\epsilon_R\} < 10^{-4}$",
								color = "magenta",
								legend_pos = "out_bottom",
								additional = "axis y discontinuity=parallel",
								ymin=0.55,
								ci_flag = false,
								width = 0.35 * ratio, height = 0.35 * ratio^-1);
pl_is_epsilon_nash = plot_eq_bound!(pl_is_epsilon_nash,mutual_information_best);

group_pl_nash = @pgf GroupPlot({group_style={group_size="2 by 1", raw"horizontal sep = 60pt"},}, pl_is_gamma_nash, pl_is_epsilon_nash);



###  SENDER'S POLICY ####
#########################

# ON PATH MESSAGES
pl_on_path_messages = plot_dist(n_on_path_messages; 
								title = "on-path", 
								color = "red",
								ymin= 0, ymax = maximum(n_on_path_messages),
								height = 0.3166*ratio, width = 0.3166);
pl_on_path_messages = plot_eq_bound!(pl_on_path_messages,mutual_information_best);
# EFFECTIVE MESSAGES
pl_effective_messages = plot_dist(n_effective_messages; 
								title = "effective", 
								color = "blue",
								ymin= 0, ymax = maximum(n_on_path_messages),
								height = 0.3166*ratio, width = 0.3166);
pl_effective_messages = plot_eq_bound!(pl_effective_messages,mutual_information_best);
# SYNONIMS
pl_synonyms = plot_dist(n_on_path_messages-n_effective_messages; 
								title = "synonyms", 
								color = "green",
								ymin= 0, ymax = maximum(n_on_path_messages),
								height = 0.3166*ratio, width = 0.3166);
pl_synonyms = plot_eq_bound!(pl_synonyms,mutual_information_best);
# GROUP WORDS
group_pl_words = @pgf GroupPlot({group_style={group_size="3 by 1",raw"horizontal sep = 25pt"},}, pl_on_path_messages, pl_effective_messages, pl_synonyms);

# IS PARTITIONAL
pl_is_partitional = plot_dist(is_partitional; 
								title = "is partitional", 
								ymin = 0, ymax = 1);
pl_is_partitional = plot_avg!(pl_is_partitional, is_partitional; ci_flag = false);
pl_is_partitional = plot_eq_bound!(pl_is_partitional,mutual_information_best);


# MODAL POLICIES
bias_idxs = [1 + 5 * (2^i - 1) for i in 0:4]
group_policies_s, group_policies_r = [], []
for bias_idx in bias_idxs
	hm_modal_policy_s = plot_policy(modal_policy_s[:,:,bias_idx], raw"$\theta$", bias_idx == 1 ? raw"$m$" : "", 0:0.5:1, bias_idx == 1 ? (1:n_messages) : "", (n_states-1)/2, 1, string(raw"$b=",set_biases[bias_idx],raw"$"));
	hm_modal_policy_r = plot_policy(modal_policy_r[:,:,bias_idx], raw"$m$",  bias_idx == 1 ? raw"$a$" : "", 1:n_messages, bias_idx == 1 ? (0:0.25:1) : "", 1, (n_actions-1)/4, "");
	n_on_path_messages_modal = findlast(sum(modal_policy_s[:,:,bias_idx], dims=1) .> 0.01)[2];
	@pgf push!(hm_modal_policy_r,VLine({loosely_dashed, black}, n_on_path_messages_modal+0.5));
	@pgf push!(hm_modal_policy_s,HLine({loosely_dashed, black}, n_messages-n_on_path_messages_modal+0.5));
	push!(group_policies_s, hm_modal_policy_s)
	push!(group_policies_r, hm_modal_policy_r)
end
group_pl_policies = @pgf GroupPlot({group_style={group_size="$(length(bias_idxs)) by 2", raw"horizontal sep = 10pt", raw"vertical sep = 35pt"},}, group_policies_s..., group_policies_r...);


# MODAL POLICIES (only for sessions converged to nash)
bias_idxs = bias_idxs[any(is_gamma_nash[:,bias_idxs],dims=1)[:]]
group_policies_s_nash, group_policies_r_nash = [], []
for bias_idx in bias_idxs
	hm_modal_policy_s_nash = plot_policy(modal_policy_s_nash[:,:,bias_idx], raw"$\theta$", bias_idx == 1 ? raw"$m$" : "", 0:0.5:1, bias_idx == 1 ? (1:n_messages) : "", (n_states-1)/2, 1, string(raw"$b=",set_biases[bias_idx],raw"$"));
	hm_modal_policy_r_nash = plot_policy(modal_policy_r_nash[:,:,bias_idx], raw"$m$",  bias_idx == 1 ? raw"$a$" : "", 1:n_messages, bias_idx == 1 ? (0:0.25:1) : "", 1, (n_actions-1)/4, "");
	n_on_path_messages_modal = findlast(sum(modal_policy_s_nash[:,:,bias_idx], dims=1) .> 0.01)[2];
	@pgf push!(hm_modal_policy_r_nash,VLine({loosely_dashed, black}, n_on_path_messages_modal+0.5));
	@pgf push!(hm_modal_policy_s_nash,HLine({loosely_dashed, black}, n_messages-n_on_path_messages_modal+0.5));
	push!(group_policies_s_nash, hm_modal_policy_s_nash)
	push!(group_policies_r_nash, hm_modal_policy_r_nash)
end
group_pl_policies_nash = @pgf GroupPlot({group_style={group_size="$(length(bias_idxs)) by 2", raw"horizontal sep = 10pt", raw"vertical sep = 35pt"},}, group_policies_s_nash..., group_policies_r_nash...);

pl_freq_ia_nash = init_tikz_axis(title = raw"p(mode)", ymin=0, ymax=1)
pl_freq_ia = init_tikz_axis(title = raw"p(mode)", ymin=0, ymax=1)
pl_freq_ia_nash = plot_val!(pl_freq_ia_nash,freq_ia_nash/n_simulations)
pl_freq_ia = plot_val!(pl_freq_ia,freq_ia/n_simulations)

# save plots
pdf_dir = mkpath(joinpath(input_dir,"pdf"))
tikz_dir = mkpath(joinpath(input_dir,"tikz"))

function save_plots(tikz_dir, pdf_dir, file_name, plot)
    pgfsave(joinpath(tikz_dir, "$file_name.tikz"), plot)
    pgfsave(joinpath(pdf_dir, "$file_name.pdf"), plot)
end

plots = [
    	("mutual_information", pl_mutual_information),
    	("mutual_information_modal", pl_modal_mutual_information),
    	("mutual_information_modal_nash", pl_modal_mutual_information_nash),
    	("group_expected_rewards", group_pl_expected_rewards),
    	("group_expected_rewards_modal", group_pl_modal_expected_rewards),
    	("group_expected_rewards_modal_nash", group_pl_modal_expected_rewards_nash),
       	("group_policies", group_pl_policies),
       	("group_policies_nash", group_pl_policies_nash),
    	("group_errors", group_pl_errors),
    	("group_nash", group_pl_nash),
    	("group_words", group_pl_words),
    	("is_partitional", pl_is_partitional),
    	("n_episodes", pl_n_episodes),
    	("freq_ia_nash", pl_freq_ia_nash),
    	("freq_ia", pl_freq_ia),
	]

counter = Atomic{Int}(0)
total_plots = length(plots)

Threads.@threads for (file_name, plot) in plots
    save_plots(tikz_dir, pdf_dir, file_name, plot)
    atomic_add!(counter, 1)
    print("\rGenerating plots $(counter[])/$total_plots")
    flush(stdout)
end
println()


#=

# compute set of nash equilibria 
set_nash = get_monotone_equilibria()
nash_induced_actions = set_nash["induced_actions"]
nash_mutual_information = set_nash["mutual_information"]
n_nash = set_nash["n_nash"]
# assign nash id (only converged sessions), nash_id = 0 for non-nash
nash_id = mapslices(x -> (idx = findfirst(all(abs.(nash_induced_actions .- x) .< 0.01, dims=1:2)[:]); idx === nothing ? 0 : idx), induced_actions, dims=1:2)[:]
	# compute mutual information rank
nash_ranks = [sum(unique(nash_mutual_information) .> x) + 1 for x in nash_mutual_information]
# compute rank (only converged sessions), rank = 0 for non-nash
ranks = copy(nash_id)
ranks[nash_id.!=0] = nash_ranks[nash_id[nash_id.!=0]]
ranks[nash_id.==0] .= 0

# compute frequence nash id (only converged sessions)
#freq_nash_id = map(i -> count(==(i), nash_id), 1:n_nash) / n_converged
# compute frequence of ranks (only converged sessions)
#freq_ranks = map(i -> count(==(i), ranks), 1:maximum(ranks)) / n_converged





changes = findall(benchmark[1:end-1] .!= benchmark[2:end]) .+ 1
pushfirst!(changes,1)
push!(changes,length(benchmark))
midpoints = div.((changes[1:end-1] .+ changes[2:end]),2)
x_coords = set_biases_[midpoints]
y_coords = benchmark[midpoints] .- (benchmark[1] - benchmark[end]) / 100
labels = Int.(best_nash["best_n_messages_on_path"][changes[1:end-1]])
for i in eachindex(x_coords)
    latex_string = "\\node at (axis cs:$(x_coords[i]),$(y_coords[i])) [anchor=south, red, opacity=0.5] {\\tiny \$$(labels[i])\$};"
    push!(pl, PGFPlotsX.Expression(latex_string))
end


data_ = mapslices(x->mode(x),extracted_data["ranks"],dims=1)
plot(data_', xticks=(1:div(n_steps-1,5):n_steps,set_biases_[1:div(n_steps-1,5):n_steps]),ylabel="y-th best", xlabel="bias", c=:red, ylim=(0,10),yticks=1:10)

=#


