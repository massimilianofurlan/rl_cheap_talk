# This script generates plots from the simulations outcomes generated by 2_script.jl
# Usage:
# 1) navigate to the project directory 'rl_cheap_talk' 
# 2) run 'julia --threads NUM_THREADS scripts/generate_plots_2.jl -i INPUT_DIR'
#	 replacing NUM_THREADS with the desired number of threads 
#    and INPUT_DIR with the output directory of 2_script.jl 

# load dependencie
using PGFPlotsX
using StatsBase
using Base.Threads

include(joinpath(pwd(),"scripts/plots.jl"))
include(joinpath(pwd(),"scripts/read_data.jl"))

# parse terminal config
const scrpt_config = merge(parse_commandline("out_grid_search", 0.01f0),TOML.parsefile("scripts/2_config.toml"))
# define set of biases 
const set_biases = collect(0.00f0:scrpt_config["step_bias"]:0.5f0)
# define input dir 
const input_dir = joinpath(pwd(), scrpt_config["in_dir"])

# set of alphas to loop over
const set_alpha::Array{Float32,1} = [scrpt_config["min_alpha"]*2^(i-1) for i in 1:scrpt_config["n_alpha"]]
const set_lambda::Array{Float32,1} = [scrpt_config["min_lambda"]/2^(i-1) for i in 1:scrpt_config["n_lambda"]]
#const set_alpha::Array{Float32,1} = [scrpt_config["min_alpha"] + 0.05*(i-1) for i in 1:scrpt_config["n_alpha"]]
#const set_lambda::Array{Float32,1} = [scrpt_config["min_lambda"]/i for i in 1:scrpt_config["n_lambda"]]

println("\nInput dir: ", scrpt_config["in_dir"])

n_alpha, n_lambda, n_biases, n_simulations = length(set_alpha), length(set_lambda), length(set_biases), 1000

mutual_information = fill(NaN, n_alpha, n_lambda, n_simulations, n_biases);
expected_reward_s = fill(NaN, n_alpha, n_lambda, n_simulations, n_biases);
expected_reward_r = fill(NaN, n_alpha, n_lambda, n_simulations, n_biases);
max_max_mass_on_suboptim = fill(NaN, n_alpha, n_lambda, n_simulations, n_biases);
max_absolute_error = fill(NaN, n_alpha, n_lambda, n_simulations, n_biases);
is_nash = fill(NaN, n_alpha, n_lambda, n_simulations, n_biases);
n_episodes = fill(NaN, n_alpha, n_lambda, n_simulations, n_biases);
is_converged = fill(NaN, n_alpha, n_lambda, n_simulations, n_biases);
ranks = fill(NaN, n_alpha, n_lambda, n_simulations, n_biases);
babbling_reward_r = fill(NaN, n_alpha, n_lambda, n_biases);

for dir in readdir(input_dir, join = true)
	isdir(dir) || continue
	println("\nCurrent dir: ", basename(dir))
	config, extracted_data = read_data(dir)
	config != nothing || continue # 
	alpha::Float32, lambda::Float32 = config["alpha_s"], config["lambda_s"]
	alpha_idx, lambda_idx = findfirst(set_alpha .== alpha), findfirst(set_lambda .== lambda)

	expected_reward_s[alpha_idx,lambda_idx,:,:] .= cat(extracted_data["expected_reward_s"]...,dims=2);
	expected_reward_r[alpha_idx,lambda_idx,:,:] .= cat(extracted_data["expected_reward_r"]...,dims=2);
	mutual_information[alpha_idx,lambda_idx,:,:] .= cat(extracted_data["mutual_information"]...,dims=2);
	max_max_mass_on_suboptim[alpha_idx,lambda_idx,:,:] .= cat(extracted_data["max_max_mass_on_suboptim"]...,dims=2);
	max_absolute_error[alpha_idx,lambda_idx,:,:] .= cat(extracted_data["max_absolute_error"]...,dims=2);
	is_nash[alpha_idx,lambda_idx,:,:] .= cat(extracted_data["max_max_mass_on_suboptim"]...,dims=2) .< 1f-2 
	n_episodes[alpha_idx,lambda_idx,:,:] .= cat(extracted_data["n_episodes"]...,dims=2);
	is_converged[alpha_idx,lambda_idx,:,:] .= cat(extracted_data["is_converged"]...,dims=2);
	babbling_reward_r[alpha_idx,lambda_idx,:] .= extracted_data["babbling_reward_r"]
end

mean_(x; dims=:) = dropdims(mean(x,dims=dims),dims=dims)
avg_expected_reward_s = mean_(expected_reward_s,dims=3)
avg_expected_reward_r = mean_(expected_reward_r,dims=3)
avg_mutual_information = mean_(mutual_information,dims=3)
avg_max_max_mass_on_suboptim = mean_(max_max_mass_on_suboptim,dims=3)
avg_max_absolute_error = mean_(max_absolute_error,dims=3)
avg_is_nash = mean_(is_nash,dims=3)
avg_n_episodes = mean_(n_episodes,dims=3)
avg_is_converged = mean_(is_converged,dims=3)

set_nash, best_nash = get_equilibria(1001)

# colden ratio
const ratio = 4/3

push!(PGFPlotsX.CUSTOM_PREAMBLE, raw"\usepgfplotslibrary{fillbetween}")

format_scientific(x) = string(round(x / 10.0^floor(Int, log10(abs(x))), digits=2), " \\times 10^{", floor(Int, log10(abs(x))), "}")

pls_expected_reward_r = Axis[]
pls_mutual_information = Axis[]
pls_is_gamma_nash = Axis[]
for alpha_idx in 5:-1:1, lambda_idx in 1:1:5
	ylabel_ = lambda_idx == 1 ? string(raw"$",set_alpha[alpha_idx],raw"$") : ""
	xlabel_ = alpha_idx == 1 ? string(raw"$",format_scientific(set_lambda[lambda_idx]),raw"$") : ""
	ylabel_ = lambda_idx == 1 && alpha_idx == 3 ? string(raw"$\alpha$ \quad $",set_alpha[alpha_idx],raw"$") : ylabel_
	xlabel_ = alpha_idx == 1 && lambda_idx == 3 ? string(raw"$",format_scientific(set_lambda[lambda_idx]),raw"$ \\[5pt] $\lambda$") : xlabel_
	axis_style = lambda_idx == 3 && alpha_idx == 3 ? "axis line style={line width=0.75pt}" : ""

	# EXPECTED REWARD RECEIVER
	#pl_expected_reward_r = plot_dist(expected_reward_r[alpha_idx,lambda_idx,:,:];
	#								ylabel = ylabel_, xlabel = xlabel_,
	#								color = "blue",
	#								additional = "ticks=none",
	#								width = 0.375, height = 0.375 * ratio^(-1));
	#pl_expected_reward_r = plot_val!(pl_expected_reward_r, best_nash["best_expected_reward_r"]; color = "red", style = "solid, line width=1.8pt", opacity = 0.4);
	#pl_expected_reward_r = plot_val!(pl_expected_reward_r, babbling_reward_r[alpha_idx,lambda_idx,:]; color = "darkgray", style = "dotted");
	#pl_expected_reward_r = plot_eq_bound!(pl_expected_reward_r);

	# MUTUAL INFORMATION
	pl_mutual_information = plot_dist(mutual_information[alpha_idx,lambda_idx,:,:];
									ylabel = ylabel_, xlabel = xlabel_,
									color = "blue",
									ymin=0, ymax=1, n_steps=65,
									additional = "ticks=none",
									width = 0.375, height = 0.375 * ratio^(-1));
	pl_mutual_information = plot_interpolated_val!(pl_mutual_information, best_nash["mutual_information"]; color = "red", style = "solid, line width=1.8pt", opacity = 0.4, ymin=0, ymax=1, n_steps=65);
	babbling_mutual_information = fill(best_nash["mutual_information"][end],length(set_biases))
	pl_mutual_information = plot_val!(pl_mutual_information, babbling_mutual_information; color = "darkgray", style = "dotted");
	pl_mutual_information = plot_eq_bound!(pl_mutual_information,best_nash["mutual_information"]);

	# IS NASH
	pl_is_gamma_nash = plot_avg(is_nash[alpha_idx,lambda_idx,:,:];
									ylabel = ylabel_, xlabel = xlabel_,
									color = "green!80!black",
									ymin=0,
									ci_flag = false,
									additional = string("ticks=none, ",axis_style),
									width = 0.27, height = 0.27 * ratio^(-1));
	pl_is_gamma_nash = plot_eq_bound!(pl_is_gamma_nash,best_nash["mutual_information"]);
	@pgf push!(pl_is_gamma_nash, HLine({"color = gray", "style = dashed, very thin", "on layer = axis background"}, 0))
	@pgf push!(pl_is_gamma_nash, HLine({"color = gray", "style = dashed, very thin", "on layer = axis background"}, 1))

	push!(pls_mutual_information, pl_mutual_information)
	push!(pls_is_gamma_nash, pl_is_gamma_nash)
end

group_pl_mutual_information = @pgf GroupPlot(
							{ group_style = { group_size="3 by 3", raw"horizontal sep = 10pt", raw"vertical sep = 10pt" },
   							 }, pls_mutual_information[[1,3,5,11,13,15,21,23,25]]...);

group_pl_is_gamma_nash = @pgf GroupPlot(
							{ group_style = { group_size="5 by 5", raw"horizontal sep = 5pt", raw"vertical sep = 5pt" },
   							 }, pls_is_gamma_nash...);



# save plots
pdf_dir = mkpath(joinpath(input_dir,"pdf"))
tikz_dir = mkpath(joinpath(input_dir,"tikz"))

function save_plots(tikz_dir, pdf_dir, file_name, plot)
    pgfsave(joinpath(tikz_dir, "$file_name.tikz"), plot)
    pgfsave(joinpath(pdf_dir, "$file_name.pdf"), plot)
end

plots = [
    	("grid_mutual_information", group_pl_mutual_information),
       	("grid_is_gamma_nash", group_pl_is_gamma_nash),
	]

counter = Atomic{Int}(0)
total_plots = length(plots)

Threads.@threads for (file_name, plot) in plots
    save_plots(tikz_dir, pdf_dir, file_name, plot)
    atomic_add!(counter, 1)
    print("\rGenerating plots $(counter[])/$total_plots")
    flush(stdout)
end
println()



exit()


function tikz_heatmap(matrix; title = "", xlabel = "", ylabel = "", width = 0.5, height = 0.5, clim = (0,1))
 	x = repeat(1:size(matrix,1), outer = size(matrix,2))
	y = repeat(1:size(matrix,2), inner = size(matrix,1))
	coord = Coordinates(x, y; meta = vec(matrix[end:-1:1,:]'))

	plot_ = @pgf Axis(
	    {
	        point_meta_min = clim[1],
			point_meta_max = clim[2],
 			"colormap={reversed blackwhite}{gray(0cm)=(1); gray(1cm)=(0)}",
	        #"colormap={sampled}{samples of colormap=(5 of reversed blackwhite)}", 
	        "colormap access=piecewise constant",
			"colorbar horizontal",
	        "colorbar sampled",
			enlargelimits = false,
	    },
	    PlotInc(
	        {
	            matrix_plot,
	            mark = "",
	            point_meta = "explicit",
	            "mesh/cols" = size(matrix,1)
	        },
	        coord,
	    ),
	)	
	return plot_
end

const bias_idxs = [1, 3, 8, 18, 38]

clim = (0.0,1.0)
heatmaps_ = [tikz_heatmap(avg_mutual_information[:,:,bias_idx], title = string(raw"$b=",set_biases[bias_idx],raw"$"), ylabel = bias_idx == bias_idxs[1] ? raw"$\alpha$" : "", xlabel=raw"$\lambda$", clim = clim, width = 0.5, height = 0.5) for bias_idx in bias_idxs]
group = @pgf GroupPlot({group_style = { group_size="5 by 1", raw"horizontal sep = 30pt"},}, heatmaps_...)



best_nash = get_best_nash_equilibria(51)
# fixed lambda, effect of alpha 
plot([avg_expected_reward_r[i, 3, :] for i in 1:5], c=[RGB(1-(5-i)/10, 1-(5-i)/10, 1) for i in 4:-1:0]')
plot!(best_nash["best_expected_reward_r"], c=:red)

# mean lambda, effect of alpha 
plot([mean(avg_expected_reward_r[i, 1:end, :],dims=1)[:] for i in 1:5], c=[RGB(1-(5-i)/10, 1-(5-i)/10, 1) for i in 4:-1:0]')
plot!(best_nash["best_expected_reward_r"], c=:red)

# fixed alpha, effect of lambda 
plot([avg_expected_reward_r[3, i, :] for i in 1:5], c=[RGB(1-(5-i)/10, 1-(5-i)/10, 1) for i in 4:-1:0]')
plot!(best_nash["best_expected_reward_r"], c=:red)

# mean alpha, effect of lambda 
plot([mean(avg_expected_reward_r[:, i, :],dims=1)[:] for i in 1:5], c=[RGB(1-(5-i)/10, 1-(5-i)/10, 1) for i in 4:-1:0]')
plot!(best_nash["best_expected_reward_r"], c=:red)




# MUTUAL INFORMATION 
pl_mutual_information = plot_dist(mutual_information[1,2,:,:];
								title = "normalized mutual information", 
								legend = "simulations", 
								#ylabel = raw"$I$",
								color = "blue",
								legend_pos = "out_bottom",
								ymin=0, ymax=1);
pl_mutual_information = plot_val!(pl_mutual_information, best_nash["best_mutual_information"]; legend = "optimal equilibrium", color = "red", style = "solid, thick", opacity = 0.7);
babbling_mutual_information = fill(best_nash["best_mutual_information"][end],length(set_biases))
pl_mutual_information = plot_val!(pl_mutual_information, babbling_mutual_information; legend = "babbling equilibrium", color = "darkgray", style = "dotted");
pl_mutual_information = plot_eq_bound!(pl_mutual_information);




data = mutual_information
_, _, n_simulations, n_biases = size(data)
set_biases_ = range(0.0,0.5,n_biases)
ymax = 1.0
ymin = 0.0
step_size = (ymax - ymin) / n_steps
support = range(ymin - step_size/2, ymax + step_size/2, n_steps)

h_data_(i,j) = hcat([fit(Histogram, data[i,j,:,b], support).weights for b in 1:n_biases]...)

custom_gradient = cgrad([:white, :blue], [0, 1], categorical=false)
heatmap(h_data, c=custom_gradient)

pls = plot([heatmap(h_data_(i,j), ticks=nothing, c=custom_gradient, colorbar=false) for j in 1:2:10, i in 9:-2:1]...,layout=(5,5))

for pl in pls.subplots
	plot!(pl,best_nash["best_mutual_information"]*(n_steps-1) .+0.5, labels=false)
end

plot([plot(avg_is_nash[i,j,:], labels=false, ticks=false, ylim=(0,1)) for j in 1:2:10, i in 10:-2:1]...,layout=(5,5))

plot([plot(dropdims(mapslices(x->mode(x),ranks,dims=3),dims=3)[i,j,:], labels=false, ticks=false, ylim=(0,8)) for j in 1:2:10, i in 9:-2:1]...,layout=(5,5))


# time to converge
 heatmap(mean(avg_n_episodes,dims=3)[:,:,1])



